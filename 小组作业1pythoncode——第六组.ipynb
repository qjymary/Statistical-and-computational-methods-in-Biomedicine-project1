{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "335c43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的包\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from skopt import BayesSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "data1 = pyreadr.read_r(\"CD.Rdata\")\n",
    "X_train = data1[\"X_train\"]#feature\n",
    "X_test = data1[\"X_test\"]\n",
    "y_train = data1[\"y_train\"]#target\n",
    "#是否有缺失值\n",
    "sum(pd.isnull(X_train).any())\n",
    "sum(pd.isnull(X_test ).any())\n",
    "sum(pd.isnull(y_train).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取基于BH方法变量筛选方法处理后的X_train、X_test数据\n",
    "X_BH= pd.read_csv(\"X_BH.csv\")\n",
    "X_test_BH = pd.read_csv(\"X_test_BH.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c9518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_BH= pd.read_csv(\"D:/生物医疗统计方法/X_BH.csv\")\n",
    "y_train = pd.read_csv(\"D:/生物医疗统计方法/y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1baf7d",
   "metadata": {},
   "source": [
    "# 基本分类模型和集成学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc74b54e",
   "metadata": {},
   "source": [
    "## 利用网格搜索进行初步探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe192365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是循环 1\n"
     ]
    }
   ],
   "source": [
    "# 初始化 AUC 列表\n",
    "auc_scores = []\n",
    "\n",
    "# 循环运行 50 次\n",
    "for i in range(1,51):\n",
    "    # 将基因型数据和表现型数据划分为训练集和测试集\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_BH, y_train, test_size=0.3, random_state=i)\n",
    "    \n",
    "    #knn模型\n",
    "    k_values = list(range(20, 31))  # 设置K值的候选范围\n",
    "    auc_score_knn = []   # 用于保存每个K值下的交叉验证AUC结果\n",
    "    for k in k_values:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k,p = 1,metric = 'minkowski')\n",
    "        auc = np.mean(cross_val_score(clf, X_train1, y_train1, cv=5, scoring=\"roc_auc\"))\n",
    "        auc_score_knn.append(auc)  # 在x_train上进行交叉验证，计算每个K值下的AUC\n",
    "    best_k = k_values[np.argmax(auc_score_knn)]  # 找到表现最佳的K值\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=best_k,p = 1,metric = 'minkowski')  # 创建KNN模型\n",
    "    model_knn.fit(X_train1, y_train1)   # 在整个x_train上训练模型\n",
    "    y_pred = model_knn.predict(X_test1)  # 使用训练好的模型对测试数据进行预测\n",
    "    auc_scores.append(roc_auc_score(y_test1, y_pred))   # 计算AUC\n",
    "    \n",
    "    #logistic regression\n",
    "    lr = LogisticRegression(random_state=i)\n",
    "    lr_param_grid = {'C': [0.1, 1.0, 10.0]}\n",
    "    lr_grid_search = GridSearchCV(lr, lr_param_grid, scoring='roc_auc', cv=5)\n",
    "    lr_grid_search.fit(X_train1, y_train1)\n",
    "    lr_best_model = lr_grid_search.best_estimator_\n",
    "    lr_auc = roc_auc_score(y_test1, lr_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(lr_auc)\n",
    "    \n",
    "    #Trees\n",
    "    param = [{'max_depth': np.arange(3,20,3),'min_samples_leaf':np.arange(6,10,2),\n",
    "              'criterion':['gini','entropy']}]\n",
    "    tlf = GridSearchCV(DecisionTreeClassifier(random_state=i),param_grid=param,cv=5)  \n",
    "    # 在x_train上使用网格搜索法选择最佳参数（其中蕴含着交叉验证）\n",
    "    tlf.fit(X_train1, y_train1)\n",
    "    model_tree = DecisionTreeClassifier(criterion=tlf.best_params_[\"criterion\"],\n",
    "                                        max_depth=tlf.best_params_[\"max_depth\"],\n",
    "                               min_samples_leaf=tlf.best_params_[\"min_samples_leaf\"])\n",
    "    # 利用局部表现最好的参数值建立决策树分类模型\n",
    "    model_tree.fit(X_train1, y_train1)\n",
    "    y_pred = model_tree.predict_proba(X_test1)[:, 1]\n",
    "    auc_scores.append(roc_auc_score(y_test1, y_pred))\n",
    "    \n",
    "    # 随机森林模型\n",
    "    rf = RandomForestClassifier(random_state=i)\n",
    "    rf_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [1, 5, 10]}\n",
    "    rf_grid_search = GridSearchCV(rf, rf_param_grid, scoring='roc_auc', cv=5)\n",
    "    rf_grid_search.fit(X_train1, y_train1)\n",
    "    rf_best_model = rf_grid_search.best_estimator_\n",
    "    rf_auc = roc_auc_score(y_test1, rf_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(rf_auc)\n",
    "\n",
    "\n",
    "    # GBDT模型\n",
    "    gbdt = GradientBoostingClassifier(random_state=i)\n",
    "    gbdt_param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7]}\n",
    "    gbdt_grid_search = GridSearchCV(gbdt, gbdt_param_grid, scoring='roc_auc', cv=5)\n",
    "    gbdt_grid_search.fit(X_train1, y_train1)\n",
    "    gbdt_best_model = gbdt_grid_search.best_estimator_\n",
    "    gbdt_auc = roc_auc_score(y_test1, gbdt_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(gbdt_auc)\n",
    "\n",
    "    # SVM模型\n",
    "    svm = SVC(probability=True, random_state=i)\n",
    "    svm_param_grid = {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'rbf']}\n",
    "    svm_grid_search = GridSearchCV(svm, svm_param_grid, scoring='roc_auc', cv=5)\n",
    "    svm_grid_search.fit(X_train1, y_train1)\n",
    "    svm_best_model = svm_grid_search.best_estimator_\n",
    "    svm_auc =roc_auc_score(y_test1, svm_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(svm_auc)\n",
    "\n",
    "    # LightGBM模型\n",
    "    lgbm = lgb.LGBMClassifier(random_state=i)\n",
    "    gbm_param_grid = {'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7]}\n",
    "    gbm_grid_search = GridSearchCV(lgbm, gbm_param_grid, scoring='roc_auc', cv=5)\n",
    "    gbm_grid_search.fit(X_train1, y_train1)\n",
    "    gbm_best_model = gbm_grid_search.best_estimator_\n",
    "    gbm_auc = roc_auc_score(y_test1, gbm_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(gbm_auc)\n",
    "    \n",
    "    \n",
    "    #XGBoost\n",
    "    xgb = XGBClassifier(random_state=i)\n",
    "    xgb_param_grid = {\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.05, 0.1, 0.3],\n",
    "        'min_child_weight':[3, 4, 5, 6]\n",
    "    }\n",
    "    xgb_grid_search = GridSearchCV(xgb, xgb_param_grid, scoring='roc_auc', cv=5)\n",
    "    xgb_grid_search.fit(X_train1, y_train1)\n",
    "    xgb_best_model = xgb_grid_search.best_estimator_\n",
    "    xgb_auc = roc_auc_score(y_test1, xgb_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(xgb_auc)\n",
    "    print(\"这是循环\",i)\n",
    "    \n",
    "#将数据放进表格\n",
    "auc_scores =pd.DataFrame(data=auc_scores)\n",
    "auc_scores.to_csv('auc_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8f9cd",
   "metadata": {},
   "source": [
    "## 基于贝叶斯优化进一步调参优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed2969",
   "metadata": {},
   "source": [
    "以下代码由于运算时间问题所以没有写在一个for循环下面，但是通过设置相同的随机种子来控制对于不同方法的训练集和测试集相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b82d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightGBM循环50次\n",
    "n_iterations = 50\n",
    "auc_scores_lightGBM_BH = []\n",
    "time_lightGBM_BH = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_BH, y_train, test_size=0.3, random_state=i)#设置了随机数种子\n",
    "\n",
    "    # 定义LightGBM分类器\n",
    "    lgb_classifier = lgb.LGBMClassifier(random_state=i)\n",
    "\n",
    "    # 定义参数空间\n",
    "    param_space = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'n_estimators': (50, 500),\n",
    "        'max_depth': (1, 10),\n",
    "        'num_leaves': (10, 100),\n",
    "        'min_child_samples': (1, 20),\n",
    "        'subsample': (0.1, 1.0, 'uniform'),\n",
    "        'colsample_bytree': (0.1, 1.0, 'uniform')\n",
    "    }\n",
    "\n",
    "    # 使用贝叶斯优化进行参数调优\n",
    "    optimizer = BayesSearchCV(lgb_classifier, param_space, scoring='roc_auc', cv=3, n_iter=50, n_jobs=-1)\n",
    "    optimizer.fit(X_train1, y_train1)\n",
    "\n",
    "    # 输出最优参数\n",
    "    print(f\"Iteration {i+1}: Best params - {optimizer.best_params_}\")\n",
    "\n",
    "    # 在测试集上进行预测\n",
    "    y_pred = optimizer.predict_proba(X_test1)[:, 1]\n",
    "\n",
    "    # 计算AUC得分\n",
    "    auc = roc_auc_score(y_test1, y_pred)\n",
    "    auc_scores_lightGBM_BH.append(auc)\n",
    "    #print(f\"Iteration {i+1}: AUC - {auc}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    time_lightGBM_BH.append(duration)\n",
    "    \n",
    "    \n",
    "auc_scores_lightGBM_BH =pd.DataFrame(data=auc_scores_lightGBM_BH)#将数据放进表格\n",
    "auc_scores_lightGBM_BH.to_csv('auc_scores_lightGBM_BH.csv')\n",
    "time_lightGBM_BH =pd.DataFrame(data=time_lightGBM_BH)#将数据放进表格\n",
    "time_lightGBM_BH.to_csv('auc_scores_lightGBM_BH.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3200620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM循环50次\n",
    "n_iterations = 50\n",
    "auc_scores_SVM_BH = []\n",
    "time_SVM_BH = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_BH, y_train, test_size=0.3, random_state=i)#设置了随机数种子\n",
    "\n",
    "\n",
    "    # 定义SVM分类器\n",
    "    svm_classifier = SVC(probability=True, random_state=i)\n",
    "\n",
    "    # 定义参数空间\n",
    "    param_space = {\n",
    "        'C': (0.01, 10.0, 'log-uniform'),\n",
    "        'gamma': (0.01, 10.0, 'log-uniform'),\n",
    "        'kernel': ('linear', 'rbf')\n",
    "    }\n",
    "\n",
    "    # 使用贝叶斯优化进行参数调优\n",
    "    optimizer = BayesSearchCV(svm_classifier, param_space, scoring='roc_auc', cv=3, n_iter=50, n_jobs=-1)\n",
    "    optimizer.fit(X_train1, y_train1)\n",
    "\n",
    "    # 输出最优参数\n",
    "    print(f\"Iteration {i+1}: Best params - {optimizer.best_params_}\")\n",
    "\n",
    "    # 在测试集上进行预测\n",
    "    y_pred = optimizer.predict_proba(X_test1)[:, 1]\n",
    "\n",
    "    # 计算AUC得分\n",
    "    auc = roc_auc_score(y_test1, y_pred)\n",
    "    auc_scores_SVM_BH.append(auc)\n",
    "    print(f\"Iteration {i+1}: AUC - {auc}\")\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    time_SVM_BH.append(duration)\n",
    "\n",
    "auc_scores_SVM_BH =pd.DataFrame(data=auc_scores_SVM_BH)#将数据放进表格\n",
    "auc_scores_SVM_BH.to_csv('auc_scores_SVM_BH.csv')\n",
    "time_SVM_BH =pd.DataFrame(data=time_SVM_BH)#将数据放进表格\n",
    "time_SVM_BH.to_csv('time_SVM_BH.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe693f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林循环50次\n",
    "n_iterations = 50\n",
    "auc_scores_RF_BH = []\n",
    "time_RF_BH = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_BH, y_train, test_size=0.3, random_state=i)#设置了随机数种子\n",
    "\n",
    "\n",
    "    # 定义随机森林分类器\n",
    "    rf_classifier = RandomForestClassifier(random_state=i)\n",
    "\n",
    "    # 定义参数空间\n",
    "    param_space = {\n",
    "        'n_estimators': (50, 500),\n",
    "        'max_depth': (1, 10),\n",
    "        'min_samples_split': (2, 20),\n",
    "        'min_samples_leaf': (1, 20),\n",
    "        'max_features': (0.1, 1.0, 'uniform')\n",
    "    }\n",
    "\n",
    "    # 使用贝叶斯优化进行参数调优\n",
    "    optimizer = BayesSearchCV(rf_classifier , param_space, scoring='roc_auc', cv=3, n_iter=50, n_jobs=-1)\n",
    "    optimizer.fit(X_train1, y_train1)\n",
    "\n",
    "    # 输出最优参数\n",
    "    print(f\"Iteration {i+1}: Best params - {optimizer.best_params_}\")\n",
    "\n",
    "    # 在测试集上进行预测\n",
    "    y_pred = optimizer.predict_proba(X_test1)[:, 1]\n",
    "\n",
    "    # 计算AUC得分\n",
    "    auc = roc_auc_score(y_test1, y_pred)\n",
    "    auc_scores_RF_BH.append(auc)\n",
    "    print(f\"Iteration {i+1}: AUC - {auc}\")\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    time_RF_BH.append(duration)\n",
    "\n",
    "auc_scores_RF_BH =pd.DataFrame(data=auc_scores_RF_BH)#将数据放进表格\n",
    "auc_scores_RF_BH.to_csv('auc_scores_RF_BH.csv')\n",
    "time_RF_BH_BH =pd.DataFrame(data=time_RF_BH)#将数据放进表格\n",
    "time_RF_BH.to_csv('time_RF_BH.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT循环50次\n",
    "n_iterations = 50\n",
    "auc_scores_BH_GBDT = []\n",
    "time_BH_GBDT = []\n",
    "\n",
    "# 定义参数空间\n",
    "param_space = {\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'n_estimators': (50, 500),\n",
    "    'max_depth': (1, 10),\n",
    "    'min_samples_split': (2, 20),\n",
    "    'min_samples_leaf': (1, 20),\n",
    "    'max_features': (0.1, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(n_iterations):\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_BH, y_train, test_size=0.3, random_state=i)#设置了随机数种子\n",
    "    \n",
    "    # 定义GBDT分类器\n",
    "    gbdt = GradientBoostingClassifier(random_state=i)\n",
    "    \n",
    "    # 使用贝叶斯优化进行参数调优\n",
    "    optimizer = BayesSearchCV(gbdt, param_space, scoring='roc_auc', cv=3, n_iter=50, n_jobs=-1)\n",
    "    optimizer.fit(X_train2, y_train2)\n",
    "    \n",
    "    # 输出最优参数\n",
    "    print(f\"Best params: {optimizer.best_params_}\")\n",
    "    \n",
    "    # 在测试集上进行预测\n",
    "    y_pred = optimizer.predict_proba(X_test2)[:, 1]\n",
    "    \n",
    "    # 计算AUC得分\n",
    "    auc = roc_auc_score(y_test2, y_pred)\n",
    "    auc_scores_BH_GBDT.append(auc)\n",
    "    \n",
    "    #print(\"这是循环\",i)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    time_BH_GBDT.append(duration)\n",
    "    \n",
    "    \n",
    "\n",
    "auc_scores_BH_GBDT =pd.DataFrame(data=auc_scores_BH_GBDT)#将数据放进表格\n",
    "auc_scores_BH_GBDT.to_csv('auc_scores_BH_GBDT.csv')\n",
    "time_BH_GBDT =pd.DataFrame(data=time_BH_GBDT)#将数据放进表格\n",
    "time_BH_GBDT.to_csv('time_BH_GBDT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aa2ffd",
   "metadata": {},
   "source": [
    "# 基于GBDT进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数空间\n",
    "param_space = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'n_estimators': (50, 500),\n",
    "        'max_depth': (1, 10),\n",
    "        'num_leaves': (10, 100),\n",
    "        'min_child_samples': (1, 20),\n",
    "        'subsample': (0.1, 1.0, 'uniform'),\n",
    "        'colsample_bytree': (0.1, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "    \n",
    "# 定义GBDT分类器\n",
    "lgb = lgb.LGBMClassifier(random_state=42)\n",
    "    \n",
    "# 使用贝叶斯优化进行参数调优\n",
    "optimizer = BayesSearchCV(lgb, param_space, scoring='roc_auc', cv=3, n_iter=50, n_jobs=-1)\n",
    "optimizer.fit(X_BH, y_train)\n",
    "    \n",
    "# 输出最优参数\n",
    "print(f\"Best params: {optimizer.best_params_}\")\n",
    "    \n",
    "# 在测试集上进行预测\n",
    "y_pred = optimizer.predict_proba(X_test_BH)[:, 1]\n",
    "    \n",
    "y_pred_BH_lightGBT =pd.DataFrame(data=y_pred)#将数据放进表格\n",
    "y_pred_BH_lightGBT.to_csv('y_pred_BH_lightGBT.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "103.99px",
    "width": "242.156px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
