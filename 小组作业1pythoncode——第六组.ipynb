{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c4f85c",
   "metadata": {},
   "source": [
    "The python code mainly consists of the machine learning training and prediction parts of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335c43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的包\n",
    "#load packages\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from skopt import BayesSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a3fdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取数据\n",
    "# read the data\n",
    "data1 = pyreadr.read_r(\"E:\\\\qjy\\\\ecnu\\\\大三第二学期\\\\生物医疗\\\\生物医疗小组作业1\\\\CD.Rdata\")\n",
    "X_train = data1[\"X_train\"]#feature\n",
    "X_test = data1[\"X_test\"]\n",
    "y_train = data1[\"y_train\"]#target\n",
    "#是否有缺失值\n",
    "# There is no missing value.\n",
    "sum(pd.isnull(X_train).any())\n",
    "sum(pd.isnull(X_test ).any())\n",
    "sum(pd.isnull(y_train).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa3f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取基于BH方法变量筛选方法处理后的X_train、X_test数据\n",
    "# Read the data X_train and X_test processed by the variable screening method based on BH method\n",
    "X_BH= pd.read_csv(\"E:\\\\qjy\\\\ecnu\\\\大三第二学期\\\\生物医疗\\\\生物医疗小组作业1\\\\X_BH.csv\")\n",
    "X_test_BH = pd.read_csv(\"E:\\\\qjy\\\\ecnu\\\\大三第二学期\\\\生物医疗\\\\生物医疗小组作业1\\\\X_test_BH.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58c9518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_BH= pd.read_csv(\"E:\\\\qjy\\\\ecnu\\\\大三第二学期\\\\生物医疗\\\\生物医疗小组作业1\\\\X_BH.csv\")\n",
    "y_train = pd.read_csv(\"E:\\\\qjy\\\\ecnu\\\\大三第二学期\\\\生物医疗\\\\生物医疗小组作业1\\\\y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1baf7d",
   "metadata": {},
   "source": [
    "# 基本分类模型和集成学习 Basic Classification Models and Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc74b54e",
   "metadata": {},
   "source": [
    "## 利用网格搜索进行初步探索  An initial exploration was performed using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe192365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是循环 1\n"
     ]
    }
   ],
   "source": [
    "# Initialize AUC list\n",
    "auc_scores = []\n",
    "\n",
    "# Run the loop 50 times\n",
    "for i in range(1, 51):\n",
    "    # Split genotype data and phenotype data into training and testing sets\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_BH, y_train, test_size=0.3, random_state=i)\n",
    "    \n",
    "    # KNN model\n",
    "    k_values = list(range(20, 31))  # Set the candidate range for K values\n",
    "    auc_score_knn = []   # To save cross-validation AUC results for each K value\n",
    "    for k in k_values:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, p=1, metric='minkowski')\n",
    "        auc = np.mean(cross_val_score(clf, X_train1, y_train1, cv=5, scoring=\"roc_auc\"))\n",
    "        auc_score_knn.append(auc)  # Perform cross-validation on x_train and calculate AUC for each K value\n",
    "    best_k = k_values[np.argmax(auc_score_knn)]  # Find the best performing K value\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=best_k, p=1, metric='minkowski')  # Create KNN model\n",
    "    model_knn.fit(X_train1, y_train1)   # Train the model on the entire x_train\n",
    "    y_pred = model_knn.predict(X_test1)  # Use the trained model to predict the test data\n",
    "    auc_scores.append(roc_auc_score(y_test1, y_pred))   # Calculate AUC\n",
    "    \n",
    "    # Logistic regression\n",
    "    lr = LogisticRegression(random_state=i)\n",
    "    lr_param_grid = {'C': [0.1, 1.0, 10.0]}\n",
    "    lr_grid_search = GridSearchCV(lr, lr_param_grid, scoring='roc_auc', cv=5)\n",
    "    lr_grid_search.fit(X_train1, y_train1)\n",
    "    lr_best_model = lr_grid_search.best_estimator_\n",
    "    lr_auc = roc_auc_score(y_test1, lr_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(lr_auc)\n",
    "    \n",
    "    # Decision Trees\n",
    "    param = [{'max_depth': np.arange(3, 20, 3), 'min_samples_leaf': np.arange(6, 10, 2),\n",
    "              'criterion': ['gini', 'entropy']}]\n",
    "    tlf = GridSearchCV(DecisionTreeClassifier(random_state=i), param_grid=param, cv=5)  \n",
    "    # Use grid search on x_train to select the best parameters (which includes cross-validation)\n",
    "    tlf.fit(X_train1, y_train1)\n",
    "    model_tree = DecisionTreeClassifier(criterion=tlf.best_params_[\"criterion\"],\n",
    "                                        max_depth=tlf.best_params_[\"max_depth\"],\n",
    "                               min_samples_leaf=tlf.best_params_[\"min_samples_leaf\"])\n",
    "    # Build decision tree classification model using the locally best-performing parameter values\n",
    "    model_tree.fit(X_train1, y_train1)\n",
    "    y_pred = model_tree.predict_proba(X_test1)[:, 1]\n",
    "    auc_scores.append(roc_auc_score(y_test1, y_pred))\n",
    "    \n",
    "    # Random forest model\n",
    "    rf = RandomForestClassifier(random_state=i)\n",
    "    rf_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [1, 5, 10]}\n",
    "    rf_grid_search = GridSearchCV(rf, rf_param_grid, scoring='roc_auc', cv=5)\n",
    "    rf_grid_search.fit(X_train1, y_train1)\n",
    "    rf_best_model = rf_grid_search.best_estimator_\n",
    "    rf_auc = roc_auc_score(y_test1, rf_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(rf_auc)\n",
    "\n",
    "    # GBDT model\n",
    "    gbdt = GradientBoostingClassifier(random_state=i)\n",
    "    gbdt_param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7]}\n",
    "    gbdt_grid_search = GridSearchCV(gbdt, gbdt_param_grid, scoring='roc_auc', cv=5)\n",
    "    gbdt_grid_search.fit(X_train1, y_train1)\n",
    "    gbdt_best_model = gbdt_grid_search.best_estimator_\n",
    "    gbdt_auc = roc_auc_score(y_test1, gbdt_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(gbdt_auc)\n",
    "\n",
    "    # SVM model\n",
    "    svm = SVC(probability=True, random_state=i)\n",
    "    svm_param_grid = {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'rbf']}\n",
    "    svm_grid_search = GridSearchCV(svm, svm_param_grid, scoring='roc_auc', cv=5)\n",
    "    svm_grid_search.fit(X_train1, y_train1)\n",
    "    svm_best_model = svm_grid_search.best_estimator_\n",
    "    svm_auc = roc_auc_score(y_test1, svm_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(svm_auc)\n",
    "\n",
    "    # LightGBM model\n",
    "    lgbm = lgb.LGBMClassifier(random_state=i)\n",
    "    gbm_param_grid = {'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7]}\n",
    "    gbm_grid_search = GridSearchCV(lgbm, gbm_param_grid, scoring='roc_auc', cv=5)\n",
    "    gbm_grid_search.fit(X_train1, y_train1)\n",
    "    gbm_best_model = gbm_grid_search.best_estimator_\n",
    "    gbm_auc = roc_auc_score(y_test1, gbm_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(gbm_auc)\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb = XGBClassifier(random_state=i)\n",
    "    xgb_param_grid = {\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.05, 0.1, 0.3],\n",
    "        'min_child_weight': [3, 4, 5, 6]\n",
    "    }\n",
    "    xgb_grid_search = GridSearchCV(xgb, xgb_param_grid, scoring='roc_auc', cv=5)\n",
    "    xgb_grid_search.fit(X_train1, y_train1)\n",
    "    xgb_best_model = xgb_grid_search.best_estimator_\n",
    "    xgb_auc = roc_auc_score(y_test1, xgb_best_model.predict_proba(X_test1)[:, 1])\n",
    "    auc_scores.append(xgb_auc)\n",
    "    print(\"This is iteration\", i)\n",
    "\n",
    "# Put the data into a table\n",
    "auc_scores = pd.DataFrame(data=auc_scores)\n",
    "auc_scores.to_csv('auc_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8f9cd",
   "metadata": {},
   "source": [
    "## 基于贝叶斯优化进一步调参优化  Bayesian optimization is used to further tune the hyparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed2969",
   "metadata": {},
   "source": [
    "以下代码由于运算时间问题所以没有写在一个for循环下面，但是通过设置相同的随机种子来控制对于不同方法的训练集和测试集相同\n",
    "\n",
    "The following code is not written under a for loop due to time constraints, but sets the same random seed to ensure that the training and test sets are the same for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b82d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM loop for 50 iterations\n",
    "n_iterations = 50\n",
    "auc_scores_lightGBM_BH = []\n",
    "time_lightGBM_BH = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Split the training set and testing set\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_BH, y_train, test_size=0.3, random_state=i)  # Random seed set\n",
    "\n",
    "    # Define LightGBM classifier\n",
    "    lgb_classifier = lgb.LGBMClassifier(random_state=i)\n",
    "\n",
    "    # Define parameter space\n",
    "    param_space = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'n_estimators': (50, 500),\n",
    "        'max_depth': (1, 10),\n",
    "        'num_leaves': (10, 100),\n",
    "        'min_child_samples': (1, 20),\n",
    "        'subsample': (0.1, 1.0, 'uniform'),\n",
    "        'colsample_bytree': (0.1, 1.0, 'uniform')\n",
    "    }\n",
    "\n",
    "    # Use Bayesian optimization for hyperparameter tuning\n",
    "    optimizer = BayesSearchCV(lgb_classifier, param_space, scoring='roc_auc', cv=3, n_iter=50, n_jobs=-1)\n",
    "    optimizer.fit(X_train1, y_train1)\n",
    "\n",
    "    # Output the best parameters\n",
    "    print(f\"Iteration {i+1}: Best params - {optimizer.best_params_}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = optimizer.predict_proba(X_test1)[:, 1]\n",
    "\n",
    "    # Calculate AUC score\n",
    "    auc = roc_auc_score(y_test1, y_pred)\n",
    "    auc_scores_lightGBM_BH.append(auc)\n",
    "    #print(f\"Iteration {i+1}: AUC - {auc}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    time_lightGBM_BH.append(duration)\n",
    "    \n",
    "    \n",
    "# Put the AUC scores into a table\n",
    "auc_scores_lightGBM_BH = pd.DataFrame(data=auc_scores_lightGBM_BH)\n",
    "auc_scores_lightGBM_BH.to_csv('auc_scores_lightGBM_BH.csv')\n",
    "\n",
    "# Put the time durations into a table\n",
    "time_lightGBM_BH = pd.DataFrame(data=time_lightGBM_BH)\n",
    "time_lightGBM_BH.to_csv('auc_scores_lightGBM_BH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3200620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM loop for 50 iterations\n",
    "n_iterations = 50\n",
    "auc_scores_SVM_BH = []\n",
    "time_SVM_BH = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Split the training set and testing set\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_BH, y_train, test_size=0.3, random_state=i)  # Random seed set\n",
    "\n",
    "    # Define SVM classifier\n",
    "    svm_classifier = SVC(probability=True, random_state=i)\n",
    "\n",
    "    # Define parameter space\n",
    "    param_space = {\n",
    "        'C': (0.01, 10.0, 'log-uniform'),\n",
    "        'gamma': (0.01, 10.0, 'log-uniform'),\n",
    "        'kernel': ('linear', 'rbf')\n",
    "    }\n",
    "\n",
    "    # Use Bayesian optimization for hyperparameter tuning\n",
    "    optimizer = BayesSearchCV(svm_classifier, param_space, scoring='roc_auc', cv=3, n_iter=50, n_jobs=-1)\n",
    "    optimizer.fit(X_train1, y_train1)\n",
    "\n",
    "    # Output the best parameters\n",
    "    print(f\"Iteration {i+1}: Best params - {optimizer.best_params_}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = optimizer.predict_proba(X_test1)[:, 1]\n",
    "\n",
    "    # Calculate AUC score\n",
    "    auc = roc_auc_score(y_test1, y_pred)\n",
    "    auc_scores_SVM_BH.append(auc)\n",
    "    print(f\"Iteration {i+1}: AUC - {auc}\")\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    time_SVM_BH.append(duration)\n",
    "\n",
    "# Put the AUC scores into a table\n",
    "auc_scores_SVM_BH = pd.DataFrame(data=auc_scores_SVM_BH)\n",
    "auc_scores_SVM_BH.to_csv('auc_scores_SVM_BH.csv')\n",
    "\n",
    "# Put the time durations into a table\n",
    "time_SVM_BH = pd.DataFrame(data=time_SVM_BH)\n",
    "time_SVM_BH.to_csv('time_SVM_BH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe693f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest loop for 50 iterations\n",
    "n_iterations = 50\n",
    "auc_scores_RF_BH = []\n",
    "time_RF_BH = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Split the training set and testing set\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_BH, y_train, test_size=0.3, random_state=i)  # Random seed set\n",
    "\n",
    "    # Define Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(random_state=i)\n",
    "\n",
    "    # Define parameter space\n",
    "    param_space = {\n",
    "        'n_estimators': (50, 500),\n",
    "        'max_depth': (1, 10),\n",
    "        'min_samples_split': (2, 20),\n",
    "        'min_samples_leaf': (1, 20),\n",
    "        'max_features': (0.1, 1.0, 'uniform')\n",
    "    }\n",
    "\n",
    "    # Use Bayesian optimization for hyperparameter tuning\n",
    "    optimizer = BayesSearchCV(rf_classifier, param_space, scoring='roc_auc', cv=3, n_iter=50, n_jobs=-1)\n",
    "    optimizer.fit(X_train1, y_train1)\n",
    "\n",
    "    # Output the best parameters\n",
    "    print(f\"Iteration {i+1}: Best params - {optimizer.best_params_}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = optimizer.predict_proba(X_test1)[:, 1]\n",
    "\n",
    "    # Calculate AUC score\n",
    "    auc = roc_auc_score(y_test1, y_pred)\n",
    "    auc_scores_RF_BH.append(auc)\n",
    "    print(f\"Iteration {i+1}: AUC - {auc}\")\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    time_RF_BH.append(duration)\n",
    "\n",
    "# Put the AUC scores into a table\n",
    "auc_scores_RF_BH = pd.DataFrame(data=auc_scores_RF_BH)\n",
    "auc_scores_RF_BH.to_csv('auc_scores_RF_BH.csv')\n",
    "\n",
    "# Put the time durations into a table\n",
    "time_RF_BH = pd.DataFrame(data=time_RF_BH)\n",
    "time_RF_BH.to_csv('time_RF_BH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT loop for 50 iterations\n",
    "n_iterations = 50\n",
    "auc_scores_BH_GBDT = []\n",
    "time_BH_GBDT = []\n",
    "\n",
    "# Define parameter space\n",
    "param_space = {\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'n_estimators': (50, 500),\n",
    "    'max_depth': (1, 10),\n",
    "    'min_samples_split': (2, 20),\n",
    "    'min_samples_leaf': (1, 20),\n",
    "    'max_features': (0.1, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "for i in range(n_iterations):\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Split the training set and testing set\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_BH, y_train, test_size=0.3, random_state=i)  # Random seed set\n",
    "    \n",
    "    # Define GBDT classifier\n",
    "    gbdt = GradientBoostingClassifier(random_state=i)\n",
    "    \n",
    "    # Use Bayesian optimization for hyperparameter tuning\n",
    "    optimizer = BayesSearchCV(gbdt, param_space, scoring='roc_auc', cv=3, n_iter=50, n_jobs=-1)\n",
    "    optimizer.fit(X_train2, y_train2)\n",
    "    \n",
    "    # Output the best parameters\n",
    "    print(f\"Best params: {optimizer.best_params_}\")\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = optimizer.predict_proba(X_test2)[:, 1]\n",
    "    \n",
    "    # Calculate AUC score\n",
    "    auc = roc_auc_score(y_test2, y_pred)\n",
    "    auc_scores_BH_GBDT.append(auc)\n",
    "    \n",
    "    #print(\"This is iteration\", i)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    time_BH_GBDT.append(duration)\n",
    "    \n",
    "# Put the AUC scores into a table\n",
    "auc_scores_BH_GBDT = pd.DataFrame(data=auc_scores_BH_GBDT)\n",
    "auc_scores_BH_GBDT.to_csv('auc_scores_BH_GBDT.csv')\n",
    "\n",
    "# Put the time durations into a table\n",
    "time_BH_GBDT = pd.DataFrame(data=time_BH_GBDT)\n",
    "time_BH_GBDT.to_csv('time_BH_GBDT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aa2ffd",
   "metadata": {},
   "source": [
    "# 基于GBDT进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f5fa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1493, number of negative: 2588\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195\n",
      "[LightGBM] [Info] Number of data points in the train set: 4081, number of used features: 65\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.365842 -> initscore=-0.550098\n",
      "[LightGBM] [Info] Start training from score -0.550098\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best params: OrderedDict([('colsample_bytree', 0.1), ('learning_rate', 0.2061488009860797), ('max_depth', 1), ('min_child_samples', 20), ('n_estimators', 248), ('num_leaves', 10), ('subsample', 0.9865595944653549)])\n"
     ]
    }
   ],
   "source": [
    "# Define parameter space\n",
    "param_space = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'n_estimators': (50, 500),\n",
    "        'max_depth': (1, 10),\n",
    "        'num_leaves': (10, 100),\n",
    "        'min_child_samples': (1, 20),\n",
    "        'subsample': (0.1, 1.0, 'uniform'),\n",
    "        'colsample_bytree': (0.1, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "# Define GBDT classifier\n",
    "lgb = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Use Bayesian optimization for hyperparameter tuning\n",
    "optimizer = BayesSearchCV(lgb, param_space, scoring='roc_auc', cv=3, n_iter=50, n_jobs=-1)\n",
    "optimizer.fit(X_BH, y_train)\n",
    "\n",
    "# Output the best parameters\n",
    "print(f\"Best params: {optimizer.best_params_}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = optimizer.predict_proba(X_test_BH)[:, 1]\n",
    "\n",
    "# Put predictions into a table\n",
    "y_pred_BH_lightGBT = pd.DataFrame(data=y_pred)\n",
    "y_pred_BH_lightGBT.to_csv('y_pred_BH_lightGBT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38540b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "103.99px",
    "width": "242.156px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
